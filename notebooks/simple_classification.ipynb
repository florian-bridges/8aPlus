{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12e9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be4ca9f-479c-451a-8c5b-228778309d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83338215-345c-4660-ad8e-91bfa003f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "grades = []\n",
    "grade_dict = {}\n",
    "inv_grade_dict = {}\n",
    "grade_ct = 0\n",
    "for num in range(6, 9):\n",
    "    for let in [\"A\",\"B\",\"C\"]:\n",
    "        for pls in [\"\",\"+\"]:\n",
    "            grades.append(str(num)+let+pls)\n",
    "            grade_dict[str(num)+let+pls] = grade_ct\n",
    "            inv_grade_dict[grade_ct] = str(num)+let+pls\n",
    "            grade_ct += 1\n",
    "\n",
    "print(len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd82732-4850-4790-82f9-2e76e3462db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data():\n",
    "    ids = [file_name.replace(\".json\", \"\") for file_name in os.listdir(DATA_PATH) if file_name.find(\".json\") != -1] \n",
    "    \n",
    "    data_dict = {}\n",
    "    for id in ids:\n",
    "        with open(os.path.join(DATA_PATH, id + \".json\"), \"r\") as f:\n",
    "            js = json.load(f)\n",
    "    \n",
    "        boulder = np.load(os.path.join(DATA_PATH, id + \".npz\"))[\"arr_0\"]\n",
    "    \n",
    "        data_dict[id] = {\n",
    "            \"meta_info\": js,\n",
    "            \"boulder\": boulder,\n",
    "        }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e055a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3189ed9b-6344-4d94-966b-a2a752ce830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for key in raw_data.keys():\n",
    "    grade = grade_dict[raw_data[key][\"meta_info\"][\"grade\"]]\n",
    "    boulder = raw_data[key][\"boulder\"]\n",
    "\n",
    "    X.append(np.sum(boulder, axis=0))\n",
    "    y.append([float(grade)])\n",
    "\n",
    "y = np.array(y)\n",
    "y = y/18\n",
    "X = torch.Tensor(np.array(X).astype(float))\n",
    "y = torch.Tensor(np.array(y).astype(float))\n",
    "\n",
    "train_tensor,test_tensor = random_split(TensorDataset(X, y),[0.8, 0.2])\n",
    "train_loader =  DataLoader(train_tensor, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_tensor, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6c105b9b-56e7-4105-a7ea-f38670199c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_grade(pred):\n",
    "    try:\n",
    "        return [inv_grade_dict[max(round(p[0]), 0)] for p in (pred.to(\"cpu\").numpy()*18).astype(\"float\")]\n",
    "    except:\n",
    "        return [inv_grade_dict[max(round(p), 0)] for p in (pred.to(\"cpu\").numpy()*18).astype(\"float\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ac82cc-303d-49ea-b3a0-5fb97ea06763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7fa8d2-5750-448c-b173-7309c72b76fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029e965e-3e31-4aa3-ab46-7adf468e82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, epochs=3):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "    \n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "    \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0458193a-8f73-47e3-9140-c991fee0a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16fe77b4-1712-4bdb-a669-2d1941a72efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(198, 150),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(150, 100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60431a16-219a-47a0-a84d-47ecbcb2b838",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=198, out_features=150, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=150, out_features=100, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch:  0\n",
      "loss: 0.239681  [    4/ 4000]\n",
      "loss: 0.128987  [  404/ 4000]\n",
      "loss: 0.067587  [  804/ 4000]\n",
      "loss: 0.055125  [ 1204/ 4000]\n",
      "loss: 0.160400  [ 1604/ 4000]\n",
      "loss: 0.022042  [ 2004/ 4000]\n",
      "loss: 0.048728  [ 2404/ 4000]\n",
      "loss: 0.056889  [ 2804/ 4000]\n",
      "loss: 0.039484  [ 3204/ 4000]\n",
      "loss: 0.052616  [ 3604/ 4000]\n",
      "Epoch:  1\n",
      "loss: 0.053737  [    4/ 4000]\n",
      "loss: 0.100268  [  404/ 4000]\n",
      "loss: 0.058877  [  804/ 4000]\n",
      "loss: 0.062364  [ 1204/ 4000]\n",
      "loss: 0.076304  [ 1604/ 4000]\n",
      "loss: 0.027758  [ 2004/ 4000]\n",
      "loss: 0.068248  [ 2404/ 4000]\n",
      "loss: 0.091422  [ 2804/ 4000]\n",
      "loss: 0.090538  [ 3204/ 4000]\n",
      "loss: 0.062398  [ 3604/ 4000]\n",
      "Epoch:  2\n",
      "loss: 0.057654  [    4/ 4000]\n",
      "loss: 0.065741  [  404/ 4000]\n",
      "loss: 0.047422  [  804/ 4000]\n",
      "loss: 0.135070  [ 1204/ 4000]\n",
      "loss: 0.108085  [ 1604/ 4000]\n",
      "loss: 0.036907  [ 2004/ 4000]\n",
      "loss: 0.056655  [ 2404/ 4000]\n",
      "loss: 0.102973  [ 2804/ 4000]\n",
      "loss: 0.088875  [ 3204/ 4000]\n",
      "loss: 0.087676  [ 3604/ 4000]\n",
      "Epoch:  3\n",
      "loss: 0.058349  [    4/ 4000]\n",
      "loss: 0.026714  [  404/ 4000]\n",
      "loss: 0.035350  [  804/ 4000]\n",
      "loss: 0.096753  [ 1204/ 4000]\n",
      "loss: 0.039616  [ 1604/ 4000]\n",
      "loss: 0.056551  [ 2004/ 4000]\n",
      "loss: 0.093649  [ 2404/ 4000]\n",
      "loss: 0.065707  [ 2804/ 4000]\n",
      "loss: 0.067591  [ 3204/ 4000]\n",
      "loss: 0.078982  [ 3604/ 4000]\n",
      "Epoch:  4\n",
      "loss: 0.079726  [    4/ 4000]\n",
      "loss: 0.026121  [  404/ 4000]\n",
      "loss: 0.086802  [  804/ 4000]\n",
      "loss: 0.105312  [ 1204/ 4000]\n",
      "loss: 0.058695  [ 1604/ 4000]\n",
      "loss: 0.101081  [ 2004/ 4000]\n",
      "loss: 0.098622  [ 2404/ 4000]\n",
      "loss: 0.037693  [ 2804/ 4000]\n",
      "loss: 0.083890  [ 3204/ 4000]\n",
      "loss: 0.082235  [ 3604/ 4000]\n",
      "Epoch:  5\n",
      "loss: 0.037639  [    4/ 4000]\n",
      "loss: 0.113740  [  404/ 4000]\n",
      "loss: 0.132150  [  804/ 4000]\n",
      "loss: 0.027515  [ 1204/ 4000]\n",
      "loss: 0.088030  [ 1604/ 4000]\n",
      "loss: 0.085374  [ 2004/ 4000]\n",
      "loss: 0.063306  [ 2404/ 4000]\n",
      "loss: 0.063191  [ 2804/ 4000]\n",
      "loss: 0.130270  [ 3204/ 4000]\n",
      "loss: 0.059634  [ 3604/ 4000]\n",
      "Epoch:  6\n",
      "loss: 0.092704  [    4/ 4000]\n",
      "loss: 0.026144  [  404/ 4000]\n",
      "loss: 0.086041  [  804/ 4000]\n",
      "loss: 0.051555  [ 1204/ 4000]\n",
      "loss: 0.057164  [ 1604/ 4000]\n",
      "loss: 0.025225  [ 2004/ 4000]\n",
      "loss: 0.053983  [ 2404/ 4000]\n",
      "loss: 0.082109  [ 2804/ 4000]\n",
      "loss: 0.051124  [ 3204/ 4000]\n",
      "loss: 0.079335  [ 3604/ 4000]\n",
      "Epoch:  7\n",
      "loss: 0.074645  [    4/ 4000]\n",
      "loss: 0.088606  [  404/ 4000]\n",
      "loss: 0.082796  [  804/ 4000]\n",
      "loss: 0.056764  [ 1204/ 4000]\n",
      "loss: 0.082119  [ 1604/ 4000]\n",
      "loss: 0.067054  [ 2004/ 4000]\n",
      "loss: 0.053940  [ 2404/ 4000]\n",
      "loss: 0.052874  [ 2804/ 4000]\n",
      "loss: 0.057657  [ 3204/ 4000]\n",
      "loss: 0.035194  [ 3604/ 4000]\n",
      "Epoch:  8\n",
      "loss: 0.088021  [    4/ 4000]\n",
      "loss: 0.053300  [  404/ 4000]\n",
      "loss: 0.018664  [  804/ 4000]\n",
      "loss: 0.083827  [ 1204/ 4000]\n",
      "loss: 0.061639  [ 1604/ 4000]\n",
      "loss: 0.030869  [ 2004/ 4000]\n",
      "loss: 0.070904  [ 2404/ 4000]\n",
      "loss: 0.050317  [ 2804/ 4000]\n",
      "loss: 0.073084  [ 3204/ 4000]\n",
      "loss: 0.104282  [ 3604/ 4000]\n",
      "Epoch:  9\n",
      "loss: 0.045658  [    4/ 4000]\n",
      "loss: 0.046080  [  404/ 4000]\n",
      "loss: 0.082303  [  804/ 4000]\n",
      "loss: 0.078573  [ 1204/ 4000]\n",
      "loss: 0.078422  [ 1604/ 4000]\n",
      "loss: 0.050930  [ 2004/ 4000]\n",
      "loss: 0.048414  [ 2404/ 4000]\n",
      "loss: 0.058674  [ 2804/ 4000]\n",
      "loss: 0.096042  [ 3204/ 4000]\n",
      "loss: 0.070564  [ 3604/ 4000]\n",
      "Epoch:  10\n",
      "loss: 0.095842  [    4/ 4000]\n",
      "loss: 0.093610  [  404/ 4000]\n",
      "loss: 0.067204  [  804/ 4000]\n",
      "loss: 0.082557  [ 1204/ 4000]\n",
      "loss: 0.038453  [ 1604/ 4000]\n",
      "loss: 0.109244  [ 2004/ 4000]\n",
      "loss: 0.071864  [ 2404/ 4000]\n",
      "loss: 0.046965  [ 2804/ 4000]\n",
      "loss: 0.058162  [ 3204/ 4000]\n",
      "loss: 0.145799  [ 3604/ 4000]\n",
      "Epoch:  11\n",
      "loss: 0.136078  [    4/ 4000]\n",
      "loss: 0.023270  [  404/ 4000]\n",
      "loss: 0.017924  [  804/ 4000]\n",
      "loss: 0.075978  [ 1204/ 4000]\n",
      "loss: 0.059615  [ 1604/ 4000]\n",
      "loss: 0.033216  [ 2004/ 4000]\n",
      "loss: 0.059289  [ 2404/ 4000]\n",
      "loss: 0.067390  [ 2804/ 4000]\n",
      "loss: 0.112845  [ 3204/ 4000]\n",
      "loss: 0.114512  [ 3604/ 4000]\n",
      "Epoch:  12\n",
      "loss: 0.055459  [    4/ 4000]\n",
      "loss: 0.054775  [  404/ 4000]\n",
      "loss: 0.037278  [  804/ 4000]\n",
      "loss: 0.124838  [ 1204/ 4000]\n",
      "loss: 0.088611  [ 1604/ 4000]\n",
      "loss: 0.060936  [ 2004/ 4000]\n",
      "loss: 0.070226  [ 2404/ 4000]\n",
      "loss: 0.057099  [ 2804/ 4000]\n",
      "loss: 0.032414  [ 3204/ 4000]\n",
      "loss: 0.061152  [ 3604/ 4000]\n",
      "Epoch:  13\n",
      "loss: 0.107130  [    4/ 4000]\n",
      "loss: 0.023982  [  404/ 4000]\n",
      "loss: 0.068624  [  804/ 4000]\n",
      "loss: 0.076323  [ 1204/ 4000]\n",
      "loss: 0.089662  [ 1604/ 4000]\n",
      "loss: 0.070016  [ 2004/ 4000]\n",
      "loss: 0.068495  [ 2404/ 4000]\n",
      "loss: 0.050266  [ 2804/ 4000]\n",
      "loss: 0.060386  [ 3204/ 4000]\n",
      "loss: 0.034239  [ 3604/ 4000]\n",
      "Epoch:  14\n",
      "loss: 0.049007  [    4/ 4000]\n",
      "loss: 0.056984  [  404/ 4000]\n",
      "loss: 0.077340  [  804/ 4000]\n",
      "loss: 0.079276  [ 1204/ 4000]\n",
      "loss: 0.057452  [ 1604/ 4000]\n",
      "loss: 0.088028  [ 2004/ 4000]\n",
      "loss: 0.063377  [ 2404/ 4000]\n",
      "loss: 0.061087  [ 2804/ 4000]\n",
      "loss: 0.051926  [ 3204/ 4000]\n",
      "loss: 0.084797  [ 3604/ 4000]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=3* 1e-2)\n",
    "train(train_loader, model, loss_fn, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef401500-cbde-4fdb-842a-73164abd816d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([5.5868, 4.9379, 3.9703, 5.3974], device='cuda:0') true: tensor([[3.],\n",
      "        [6.],\n",
      "        [3.],\n",
      "        [6.]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type numpy.ndarray doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print(X)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pred_, y_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pred \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m18\u001b[39m, y \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m18\u001b[39m):\n\u001b[1;32m      9\u001b[0m     lst\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m:  pred_\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m---> 12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_cls\u001b[39m\u001b[38;5;124m\"\u001b[39m: inv_grade_dict[\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpred_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m],\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_cls\u001b[39m\u001b[38;5;124m\"\u001b[39m: inv_grade_dict[\u001b[38;5;28mround\u001b[39m(y_\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])],\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mabs(pred_\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m-\u001b[39m y_\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     15\u001b[0m     })\n",
      "\u001b[0;31mTypeError\u001b[0m: type numpy.ndarray doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X).flatten()\n",
    "        print(\"pred:\", pred * 18, \"true:\", y * 18)\n",
    "        #print(X)\n",
    "        for pred_, y_ in zip(pred * 18, y * 18):\n",
    "            lst.append({\n",
    "                \"pred\":  pred_.to(\"cpu\").numpy(),\n",
    "                \"true\": y_.to(\"cpu\").numpy()[0],\n",
    "                \"pred_cls\": inv_grade_dict[round(pred_.to(\"cpu\").numpy())],\n",
    "                \"true_cls\": inv_grade_dict[round(y_.to(\"cpu\").numpy()[0])],\n",
    "                \"diff\": np.abs(pred_.to(\"cpu\").numpy() - y_.to(\"cpu\").numpy()[0])\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d697fe5-0f59-459c-bbc2-4d81e7099752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.264"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(lst)\n",
    "len(df[df[\"pred_cls\"] == df[\"true_cls\"]])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0093ca70-10f4-4714-b3ed-3ef81383c1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "      <th>pred_cls</th>\n",
       "      <th>true_cls</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.8366418</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>6C</td>\n",
       "      <td>0.163358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.7416227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6A+</td>\n",
       "      <td>6A+</td>\n",
       "      <td>0.741623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.4101424</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>6C+</td>\n",
       "      <td>0.589858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.655112</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7A+</td>\n",
       "      <td>7B</td>\n",
       "      <td>0.344888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.8900294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6B</td>\n",
       "      <td>6B</td>\n",
       "      <td>0.890029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred  true pred_cls true_cls      diff\n",
       "0  3.8366418   4.0      6B+       6C  0.163358\n",
       "1  1.7416227   1.0      6A+      6A+  0.741623\n",
       "2  4.4101424   5.0       6C      6C+  0.589858\n",
       "3   7.655112   8.0      7A+       7B  0.344888\n",
       "4  2.8900294   2.0       6B       6B  0.890029"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50adeb36-9a86-4c01-8f31-4c58f90210f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.515"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"diff\"] < 1]) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac62781a-7d6f-40d4-89e0-2126a0568519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ffd8a-c91e-4e96-895f-58c7b834d44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
